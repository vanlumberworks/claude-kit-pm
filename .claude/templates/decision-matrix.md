# Decision Matrix: [Decision Name]

**Date**: [YYYY-MM-DD]
**Decision Owner**: [Name]
**Decision Type**: [Type 1 (Irreversible) / Type 2 (Reversible)]
**Status**: [Draft / Under Review / Approved / Implemented]

---

## Decision Overview

**Decision Statement**: [One clear sentence describing what needs to be decided]

**Context**: [Why this decision is needed]

**Timeline**: [When decision must be made]

**Impact**: [Who/what is affected by this decision]

---

## Options Being Evaluated

### Option A: [Option Name]
**Description**: [Brief description]

**Pros**:
- [Pro 1]
- [Pro 2]
- [Pro 3]

**Cons**:
- [Con 1]
- [Con 2]
- [Con 3]

**Estimated Cost**: $[amount] or [X person-months]

**Timeline**: [How long to implement]

### Option B: [Option Name]
**Description**: [Brief description]

**Pros**:
- [Pro 1]
- [Pro 2]
- [Pro 3]

**Cons**:
- [Con 1]
- [Con 2]
- [Con 3]

**Estimated Cost**: $[amount] or [X person-months]

**Timeline**: [How long to implement]

### Option C: [Option Name]
**Description**: [Brief description]

**Pros**:
- [Pro 1]
- [Pro 2]
- [Pro 3]

**Cons**:
- [Con 1]
- [Con 2]
- [Con 3]

**Estimated Cost**: $[amount] or [X person-months]

**Timeline**: [How long to implement]

---

## Evaluation Criteria

### Selected Criteria and Weights

| Criterion | Weight | Definition | Why This Matters |
|-----------|--------|------------|------------------|
| User Impact | 30% | [How much does this benefit users] | [Rationale] |
| Feasibility | 25% | [How easy/hard to implement] | [Rationale] |
| Business Value | 20% | [Revenue, retention, strategic value] | [Rationale] |
| Risk | 15% | [Technical, market, execution risk] | [Rationale] |
| Speed | 10% | [Time to market] | [Rationale] |
| **Total** | **100%** | | |

**Note**: Weights were set BEFORE scoring options to avoid bias.

### Criteria Definitions

#### User Impact (30%)
**Definition**: Degree to which this option solves real user problems and improves user experience

**Scoring Guide**:
- **10/10**: Solves critical pain point for all users, massive improvement
- **7-9/10**: Solves important problem for most users, significant improvement
- **4-6/10**: Solves moderate problem for some users, noticeable improvement
- **1-3/10**: Solves minor problem for few users, minimal improvement

#### Feasibility (25%)
**Definition**: Technical complexity and resource availability to implement

**Scoring Guide**:
- **10/10**: Simple, straightforward, clear path, team has all needed skills
- **7-9/10**: Moderate complexity, some unknowns, mostly within capabilities
- **4-6/10**: Complex, significant unknowns, requires new skills/tools
- **1-3/10**: Very complex, high uncertainty, major technical challenges

#### Business Value (20%)
**Definition**: Expected impact on revenue, retention, and strategic goals

**Scoring Guide**:
- **10/10**: Major revenue impact (>$1M) or critical strategic importance
- **7-9/10**: Significant revenue impact ($250K-$1M) or high strategic value
- **4-6/10**: Moderate impact ($50K-$250K) or medium strategic value
- **1-3/10**: Minor impact (<$50K) or low strategic value

#### Risk (15%)
**Definition**: Technical, market, and execution risks (higher score = lower risk)

**Scoring Guide**:
- **10/10**: Very low risk, reversible, well-understood
- **7-9/10**: Low to moderate risk, mostly manageable
- **4-6/10**: Moderate to high risk, requires active mitigation
- **1-3/10**: High risk, difficult to mitigate, potential for failure

#### Speed (10%)
**Definition**: Time from decision to market impact

**Scoring Guide**:
- **10/10**: Immediate to 1 month
- **7-9/10**: 1-3 months
- **4-6/10**: 3-6 months
- **1-3/10**: 6+ months

---

## Scoring Matrix

### Option Scores

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Criteria        â”‚ Weight â”‚Option A â”‚Option B â”‚Option C â”‚  Winner  â”‚
â”‚                 â”‚        â”‚(Score)  â”‚(Score)  â”‚(Score)  â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ User Impact     â”‚  30%   â”‚  8/10   â”‚  6/10   â”‚  9/10   â”‚          â”‚
â”‚                 â”‚        â”‚ [2.4]   â”‚ [1.8]   â”‚ [2.7]   â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Feasibility     â”‚  25%   â”‚  6/10   â”‚  9/10   â”‚  5/10   â”‚          â”‚
â”‚                 â”‚        â”‚ [1.5]   â”‚ [2.25]  â”‚ [1.25]  â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Business Value  â”‚  20%   â”‚  7/10   â”‚  5/10   â”‚  8/10   â”‚          â”‚
â”‚                 â”‚        â”‚ [1.4]   â”‚ [1.0]   â”‚ [1.6]   â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Risk            â”‚  15%   â”‚  8/10   â”‚  6/10   â”‚  4/10   â”‚          â”‚
â”‚                 â”‚        â”‚ [1.2]   â”‚ [0.9]   â”‚ [0.6]   â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Speed           â”‚  10%   â”‚  5/10   â”‚  9/10   â”‚  3/10   â”‚          â”‚
â”‚                 â”‚        â”‚ [0.5]   â”‚ [0.9]   â”‚ [0.3]   â”‚          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ **Total Score** â”‚**100%**â”‚ **7.0** â”‚ **6.85**â”‚ **6.45**â”‚ **7.0**ðŸ†â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Calculation**: Weighted Score = (Raw Score / 10) Ã— Weight Ã— 10

---

## Detailed Scoring Rationale

### Option A: [Name]

#### User Impact: 8/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Feasibility: 6/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Business Value: 7/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Risk: 8/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Speed: 5/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

---

### Option B: [Name]

#### User Impact: 6/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Feasibility: 9/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Business Value: 5/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Risk: 6/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Speed: 9/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

---

### Option C: [Name]

#### User Impact: 9/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Feasibility: 5/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Business Value: 8/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Risk: 4/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

#### Speed: 3/10
**Rationale**: [Why this score]
- [Supporting evidence 1]
- [Supporting evidence 2]
**Sources**: [Evidence references]

---

## Sensitivity Analysis

### Weight Sensitivity

**What if User Impact weight increases from 30% to 40%?**
- Option A: 7.0 â†’ [X.X]
- Option B: 6.85 â†’ [X.X]
- Option C: 6.45 â†’ [X.X]
- **Winner changes?**: [Yes/No]

**What if Feasibility weight increases from 25% to 35%?**
- Option A: 7.0 â†’ [X.X]
- Option B: 6.85 â†’ [X.X]
- Option C: 6.45 â†’ [X.X]
- **Winner changes?**: [Yes/No]

**Analysis**: [Is the decision robust or fragile to weight changes?]

### Score Sensitivity

**What if all Option A scores increase by 1 point?**
- Option A: 7.0 â†’ [X.X]
- **Impact**: [Strengthens/weakens decision]

**What if all Option B scores increase by 1 point?**
- Option B: 6.85 â†’ [X.X]
- **Impact**: [Would it change winner?]

**Analysis**: [How sensitive is the decision to scoring variations?]

### Key Assumptions

**Assumption 1**: [Critical assumption underlying scores]
- **If wrong**: [Impact on decision]
- **Confidence**: [High/Medium/Low]

**Assumption 2**: [Critical assumption underlying scores]
- **If wrong**: [Impact on decision]
- **Confidence**: [High/Medium/Low]

**Assumption 3**: [Critical assumption underlying scores]
- **If wrong**: [Impact on decision]
- **Confidence**: [High/Medium/Low]

---

## Decision Recommendation

### Recommended Option: [Option Name]

**Total Score**: X.X/10

**Why This Option**:
1. [Key reason 1 with evidence]
2. [Key reason 2 with evidence]
3. [Key reason 3 with evidence]

**Strengths**:
- [Strength 1]
- [Strength 2]
- [Strength 3]

**Weaknesses** (to manage):
- [Weakness 1] - Mitigation: [Strategy]
- [Weakness 2] - Mitigation: [Strategy]

### Trade-offs Accepted

**We're accepting**:
- [Trade-off 1: What we're giving up]
  - **In exchange for**: [Benefit we're gaining]

- [Trade-off 2: What we're giving up]
  - **In exchange for**: [Benefit we're gaining]

### Confidence in Recommendation

**Overall Confidence**: [HIGH/MEDIUM/LOW]

**Confidence Factors**:
- Evidence quality: [Strong/Moderate/Weak]
- Score sensitivity: [Robust/Moderate/Fragile]
- Assumption validation: [Strong/Moderate/Weak]
- Stakeholder alignment: [Strong/Moderate/Weak]

**Decision Type Alignment**:
- Type 1 (Irreversible): Requires confidence â‰¥8/10 âœ“/âŒ
- Type 2 (Reversible): Requires confidence â‰¥6/10 âœ“/âŒ

---

## Alternative Approaches Considered

### Why Not Option B?

**Score**: X.X/10 (vs. winning option: Y.Y/10)

**Key Gap**: [Primary reason not chosen]

**Would reconsider if**: [Conditions under which this becomes better option]

### Why Not Option C?

**Score**: X.X/10 (vs. winning option: Y.Y/10)

**Key Gap**: [Primary reason not chosen]

**Would reconsider if**: [Conditions under which this becomes better option]

---

## Implementation Considerations

### Success Metrics

How we'll measure if this decision was correct:

| Metric | Baseline | Target | Timeline | Owner |
|--------|----------|--------|----------|-------|
| [Metric 1] | X | Y | [Date] | [Name] |
| [Metric 2] | A | B | [Date] | [Name] |
| [Metric 3] | M | N | [Date] | [Name] |

### Key Milestones

- **Milestone 1**: [Description] - [Date]
- **Milestone 2**: [Description] - [Date]
- **Milestone 3**: [Description] - [Date]

### Resource Requirements

**Budget**: $[amount]
- Development: $[amount]
- Design: $[amount]
- Marketing: $[amount]
- Other: $[amount]

**Team**:
- Engineering: [X people for Y time]
- Design: [X people for Y time]
- PM: [X people for Y time]
- Other: [X people for Y time]

**Timeline**: [Total duration]

### Risks and Mitigation

| Risk | Probability | Impact | Mitigation | Owner |
|------|-------------|--------|------------|-------|
| [Risk 1] | H/M/L | H/M/L | [Strategy] | [Name] |
| [Risk 2] | H/M/L | H/M/L | [Strategy] | [Name] |
| [Risk 3] | H/M/L | H/M/L | [Strategy] | [Name] |

---

## Stakeholder Input

### Scoring Participation

**Who participated in scoring**:
- [Name] - [Role]
- [Name] - [Role]
- [Name] - [Role]

**Scoring Method**: [Individual scores averaged / Group consensus / PM scored with stakeholder input]

### Stakeholder Alignment

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stakeholder    â”‚ Supports      â”‚ Has Concerns    â”‚ Level of     â”‚
â”‚                â”‚ Recommendationâ”‚ About           â”‚ Agreement    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Engineering    â”‚ âœ“/âœ—           â”‚ [Concerns]      â”‚ Strong/      â”‚
â”‚                â”‚               â”‚                 â”‚ Moderate/    â”‚
â”‚                â”‚               â”‚                 â”‚ Weak         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Design         â”‚ âœ“/âœ—           â”‚ [Concerns]      â”‚ [Level]      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Sales          â”‚ âœ“/âœ—           â”‚ [Concerns]      â”‚ [Level]      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Leadership     â”‚ âœ“/âœ—           â”‚ [Concerns]      â”‚ [Level]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Alignment Score: X.X/5.0
```

### Key Stakeholder Concerns

**Concern 1**: [Stakeholder concern]
- **Raised by**: [Name/Team]
- **Addressed how**: [Response/Mitigation]

**Concern 2**: [Stakeholder concern]
- **Raised by**: [Name/Team]
- **Addressed how**: [Response/Mitigation]

---

## Review and Validation

### Decision Review Schedule

- **Check-in 1**: [Date] - Review early implementation progress
- **Check-in 2**: [Date] - Review initial metrics
- **Full Review**: [Date] - Complete assessment of decision outcome

### What Would Cause Us to Revisit

**Triggers for reassessment**:
- [Trigger 1: e.g., Key metric doesn't improve by X% in Y timeframe]
- [Trigger 2: e.g., Implementation cost exceeds budget by Z%]
- [Trigger 3: e.g., Critical assumption proves incorrect]

### Learning Capture

**After implementation, we will document**:
- What we predicted vs. what actually happened
- How accurate our scoring was
- What we would do differently next time
- Lessons learned for future decisions

**Location**: `./decisions/learnings/[decision]-retrospective-[date].md`

---

## Supporting Documents

### Evidence
- Evidence log: [Link to evidence log]
- Research synthesis: [Link to research report]
- User feedback: [Link to user research]
- Market analysis: [Link to competitive analysis]

### Related Decisions
- [Related decision 1]: [Link]
- [Related decision 2]: [Link]

### Discussion Notes
- Stakeholder meeting notes: [Link]
- Team discussion: [Link]

---

## Document History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | [Date] | [Name] | Initial decision matrix created |
| 1.1 | [Date] | [Name] | Updated after stakeholder feedback |
| 2.0 | [Date] | [Name] | Final recommendation approved |

---

## Usage Guidelines

**When to use this template**:
- Comparing 2+ distinct options
- Need systematic, objective evaluation
- Building stakeholder consensus
- Documenting decision rationale
- High-stakes or irreversible decisions

**How to complete**:
1. Define decision and options clearly
2. Select 5-7 relevant criteria (not too many)
3. Assign weights BEFORE scoring (avoid bias)
4. Define scoring rubrics for consistency
5. Score with stakeholder input
6. Calculate and analyze results
7. Perform sensitivity analysis
8. Document recommendation and rationale
9. Get stakeholder sign-off
10. Track and validate after implementation

**Tips for success**:
- Keep criteria independent (no overlap)
- Weight criteria before seeing scores
- Use evidence to support scores
- Involve relevant stakeholders in scoring
- Test sensitivity to weights and scores
- Make trade-offs explicit
- Plan for validation and learning
